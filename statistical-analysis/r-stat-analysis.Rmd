---
title: "R for Statistical analysis"
author: "Jeremy Buhler and Albina Gibadullina"
date: "April 16, 2021"
output: html_document
---

# Installing and loading R packages

This workshop uses the following R packages: 

- *psych*, a statistical analysis package
- *rstatix*, a statistical analysis package
- *dplyr*, a data manipulation package
- *ggplot2*, a data visualization package
- *GGally*, a data visualization package (extension of ggplot2)
- *table1*, a package for creating summary tables
- *lmtest*, a package for linear regression
- *stargazer*, a package for exporting regression tables
- *car*, a package for regression analysis
- *RColorBrewer*, a color palette package


Check whether required packages are already installed, and install any that are missing
```{r}
list.of.packages <- c("psych", "rstatix","dplyr","ggplot2","GGally","table1","lmtest","stargazer","car","RColorBrewer")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
```

Load packages into your current session
```{r}
suppressPackageStartupMessages({
library(psych)
library(rstatix)
library(dplyr)
library(ggplot2)
library(GGally)
library(table1)
library(lmtest)
library(stargazer)
library(car)
library(RColorBrewer)})
```


# Changing default theme for visualizations

Changing the default theme to theme_light
```{r theme_ggplot2, echo = FALSE}
theme_set(theme_light())
```

Suppress error messages
```{r package-options, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```


# Uploading data


Creating a data frame `scores` using an in-built dataset `sat.act` from the `psych` package
```{r}
scores <- sat.act
```


Importing data from a .csv file (located in your working directory)
```{r}
# scores <-read.csv("sat.act.csv") # does not work in this case as you don't have a .csv file
```


# Describing data structure


Check the description of the "sat.act" dataset
```{r}
# ?sat.act
```


See the first six rows of the data frame 
```{r}
head(scores) 
```


See the entire dataset
```{r}
#view(scores)
```


Count the number of observations (measured by the number of rows) and the number of variables (measured by the number of columns)
```{r}
nrow(scores) #To check the number of rows
ncol(scores) #To check the number of columns
```


Check data structure
```{r}
str(scores)
```


# Data manipulation


## Changing format of variables


Check current data format of the  `gender` variable
```{r}
typeof(scores$gender)
```


Change the format of `gender` from integer (quantitative) to factor (categorical)
```{r}
scores$gender <- as.factor(scores$gender)
```


Check whether `gender` has factor format
```{r}
is.factor(scores$gender)
```


## Exercise 1

* Using typeof command, check the current format of `education`
* Using as.factor command, change `education` to factor.
* Using is.factor command, check if `education` is defined as factor. 


Check current data format of the  `education` variable
```{r}

```


Change the format of `education` from integer (quantitative) to factor (categorical)
```{r}

```


Check whether `education` has factor format
```{r}

```


## Transforming values of categorical variables

### Gender

`Gender` is now factor but it is still coded as "1" (men) and "2" (women) - it would be helpful for later analysis to change "1" to "men" and "2" to "women"


Replacing values
```{r}
# Step 1: Change the data format to charachter
scores$gender <- as.character(scores$gender)

# Step 2: Replace "1" with "men" and "2" with "women"
scores$gender[scores$gender=="1"] <- "Men"
scores$gender[scores$gender=="2"] <- "Women"

# Step 3: Change the data format back to factor
scores$gender <- as.factor(scores$gender)

# Step 4: Check levels for `gender`
levels(scores$gender)
```


# Descriptive statistics


## Categorical data

Get frequency for the `gender` variable
```{r}
table(scores$gender)
```

Get cross-tabulation for `gender` and `education`
```{r}
table(scores$gender, scores$education)
```


## Quantitative data

Find summary statistics for each quantitative variable
```{r}
get_summary_stats(scores)
```


Find summary statistics for `ACT` scores, grouped by `gender`
```{r}
scores %>% 
  group_by(gender) %>%
  get_summary_stats(ACT)
```


Generated a summary statistics table, grouped by gender
```{r}
table1::table1(~education + age + ACT + SATV + SATQ | gender, data = scores)
```

# Inferential Statistics

You should select statistical tests based on your hypothesis and the data type of your variable(s)

* One sample t-test  
* Chi-square goodness of fit test 
* Two sample t-test  
* One-way ANOVA
* Two-way ANOVA
* Chi-square test of independence 
* Simple linear regression
* Multiple linear regression  
* Simple logistic regression   
* Multiple logistic regression   



## One sample t-test

It is used to see whether the hypothesized value of the population mean matches actual value.

Is the average ACT score for all participants 27?


Visualize the distribution of ACT scores using a histogram with a normal distribution curve and a line for mean
```{r}
scores %>%
  ggplot(aes(x=ACT)) + 
    geom_histogram(aes(y = stat(density)), binwidth=2, color="black", fill="lightblue") +
    stat_function(fun = dnorm, args = list(mean = mean(scores$ACT), sd = sd(scores$ACT)),size=1)+
    geom_vline(aes(xintercept = mean(ACT)), color="red") +
    labs(title="Histogram of ACT scores with a Normal Curve", x="ACT score", y="Percent of observations")
```



Run the one sample t-test
```{r}
t.test(scores$ACT,mu = 27,
       alternative = c("two.sided"),
       conf.level = 0.95)
```

t(df=699) = 8.4862, p-value = 0.00% < 5% (reject the null) -> The average ACT score is not 27.


## Chi-square goodness of fit

It is used to see whether the actual distribution (from a sample) of a categorical variable mathes the expected distribution.

Is gender distribution 50%-50% in this data set?


Make a relative bar-chart showing counts of observations by gender
```{r}
scores %>% 
  ggplot(aes(fill=gender, x=gender)) + 
    geom_bar(aes(y=stat(count)/sum(count)))+
    geom_text(aes(label = round(stat(count)/sum(count),2),y=stat(count)/sum(count)), 
              stat="count", position = position_stack(vjust = 0.5), size=5) +
    scale_fill_brewer(palette = "Dark2")+
    labs(title="Share of observations by gender",y="Percent of observations",x="Gender",fill="Gender")
```


Run a Chi-square goodness of fit
```{r}
chisq.test(table(scores$gender), p = c(0.5,0.5))
```

X-squared(df=1) = 60.623, p-value = 0.00% < 5% (reject the null) -> The gender distribution is not 50%-50%.


## Two-sample t-test

It is used to see whether there are group differences in population means between two groups.

Do men and women have different average SAT verbal scores?

Use boxplots to compare distributions of one quantitative variable across multiple categories:
```{r}
scores %>%
  ggplot(aes(x=gender, y=SATV, fill=gender))+
    geom_boxplot(outlier.size=1)+
    stat_summary(fun=mean, geom="point", shape=5, size=4)+
    scale_fill_brewer(palette = "Dark2")+
    labs(title="Boxplots of SAT Verbal scores by gender",x="Gender", y="SAT Verbal scores",fill="Gender")
```


Alternatively, use density plots to compare distributions
```{r}
scores %>%
  ggplot(aes(x=SATV, fill=gender))+
    geom_density(alpha=0.5)+
    scale_fill_brewer(palette = "Dark2")+
    labs(title="Density plots of SAT Verbal scores by gender", x="SAT Verbal scores", fill="Gender")
```


Run a two sample t-test
```{r}
t.test(scores$SATV ~ scores$gender, var.eq = TRUE)
```

t(df=698) = 0.49792, p-value = 61.87% > 5% (fail to reject the null) -> There was no statistically significant difference in average SAT verbal scores between men and women.


## One-way ANOVA

It is used to determine whether there are group differences in numeric data between two or more groups.

Question: Do SAT verbal scores significantly differ by educational levels (1= HS, 2= some college degree, 3 = 2-year college degree, 4= 4-year college degree, 5= graduate work, 6=professional degree)?

Use boxplots to compare distributions of one quantitative variable across multiple categories.

Comparing distribution of `SATV` scores variable by education level:
```{r}
scores %>%
  ggplot(aes(x=education, y=SATV, fill=education))+
    geom_boxplot(outlier.size=1)+
    labs(title="Boxplots of SAT Verbal scores by education level",
         x="Levels of education", y="SAT Verbal scores",fill="Education")
```

Run one-way ANOVA:
```{r}
ANOVA_SATV_ed <- aov(scores$SATV ~ scores$education)
summary(ANOVA_SATV_ed)
```

F value(df Model=5, df Residuals=694) = 1.269, p-value = 27.5% > 5% (fail to reject the null) -> There were no significant group differences in SAT verbal scores according to students' educational levels.


We do not have to run the post hoc tests because the group differences are not significant.


Tukey's HSD is the most popular post hoc test for comparing multiple pairings:
```{r}
Tukey_ANOVA_SATV_ed <- TukeyHSD(aov(scores$SATV ~ scores$education), conf.level=.95) 
Tukey_ANOVA_SATV_ed
```


## Two-way ANOVA

It is used to determine whether there are group differences in numeric data between groups charachterized by two different categorical variables.

Do SAT verbal scores significantly differ by educational levels and gender?

Use boxplots to compare distribution of `SATV` scores variable by education level and gender (grouped by education level first, gender second)
```{r}
scores %>%
  ggplot(aes(x=education, y=SATV, fill=gender))+
    geom_boxplot(outlier.size=1)+
    scale_fill_brewer(palette = "Dark2")+
    labs(title="Boxplots of SAT Verbal scores by education level and gender",
         x="Level of education", y="SAT Verbal score",fill="Gender")
```


Run two-way ANOVA:
```{r}
ANOVA_SATV_ed_g <- aov(scores$SATV ~ scores$education+scores$gender)

summary(ANOVA_SATV_ed_g)
```

* Education: F value(df Model=5, df Residuals=693) = 1.269, p-value = 27.6% > 5% (fail to reject the null)
* Gender: F value(df Model=1, df Residuals=693) = 0.529, p-value = 46.7% > 5% (fail to reject the null)

There were no significant group differences in SAT verbal scores according to students' educational levels or gender.



## Chi-square test of independence

It is used to determine whether two categorical variables are dependent or independent.

Is gender independent of education levels?

Make a bar-chart showing distribution of observations by gender and education
```{r}
scores %>% 
  ggplot(aes(fill=gender, x=education)) + 
    geom_bar(position = "fill")+
    scale_fill_brewer(palette = "Dark2")+
    geom_text(aes(y=..count../tapply(..count.., ..x.. ,sum)[..x..], 
                  label=scales::percent(..count../tapply(..count.., ..x.. ,sum)[..x..]) ),
                  stat="count", position = position_stack(vjust = 0.5))+  
    labs(title="Distribution of observations by gender and education levels",
         y="Number of observations",x="Education levels",fill="Gender")+
    coord_flip()
```


Run a Chi-square test of independence
```{r}
chisq.test(table(scores$gender, scores$education))
```

X-squared(df=5) = 16.085, p-value = 0.006% < 5% (reject the null) -> Gender and education levels are dependent.


## Simple linear regression 

It is used to identify a presense of a linear relationship between two quantitative variables.


Is there a linear relationship between SAT Verbal and SAT Quantitative scores?

Make a scatteplot with a best-fit line
```{r}
ggplot(scores, aes(x=SATQ, y=SATV)) + 
  geom_point()+
  geom_smooth(method=lm)+
  labs(title="Scatteplot of SAT Verbal and SAT Quantitative scores",x="SAT Quantitative score", y="SAT Verbal score")
```


Run a simple linear regression
```{r}
model1 <- lm(scores$SATV ~ scores$SATQ)
summary(model1)
```

T-test for Beta1:

* t-stat(SATQ) = 22.05, p-value = 0.00% < 5% (reject the null)
* There is a linear relationship between SAT Quantitative scores and SAT Verbal scores. 

ANOVA for Regression:

* F-stat(1,685) = 486.2, p-value = 0.00% < 5% (reject the null)
* The overall model is worthwhile.

Overall:

* The estimated regression line equation: SATV = 227.14 + 0.63(SATQ). We would expect 0.63 points increase in SAT Verbal scores for every one point increase in SAT Quantitative score, assuming all the other variables are held constant.
* 41.51% of the variability in the SAT verbal scores was explained by the SAT quantitative scores.


### Check conditions/assumptions of linear regression

* Normality of residuals: residual errors are assumed to be normally distributed.
* Homoscedasticity of residuals variance: residuals are assumed to have a constant variance
* Independence of residual error terms: residuals should be independent of each other.


### Normality

Normal Q-Q plot
```{r}
plot=plot(model1,2)
```


Checking for normality using Shapiro-Wilk test:
```{r}
shapiro.test(resid(model1))
```
p-values below 5% indicate non-normality of residuals


### Homoscedasticity

Plot positive values of residuals against fitted values
```{r}
plot=plot(model1,3)
```


Checking for heteroscedasticity using Breusch-Pagan Test
```{r}
bptest(model1)
```
p-values below 5% indicate heteroscedasticity of residuals


### Independence

Residuals vs Fitted plot
```{r}
plot=plot(model1,1)
```


Checking for auto-correlation using Durbin-Watson Test
```{r}
durbinWatsonTest(model1)
```
p-values below 5% indicate autocorrelation of residuals



## Multiple linear regression

It is used to explain/predict one quantitative variable using multiple explanatory variables (one of which has to be quantitative).


For example, can you explain/predict SAT Verbal using SAT Quantitative scores and ACT scores?

Make a correlation matrix
```{r}
scores %>%
  select(SATV,SATQ,ACT) %>% 
  ggpairs(ggplot2::aes())
```

Run a multiple linear regression
```{r}
model2 <- lm(scores$SATV ~ scores$SATQ +  scores$ACT)
summary(model2)
```


### Multicollinearity

Check Variance Inflation Factor (VIF) for the severity of multicollinearity
```{r}
vif(model2)
```
VIF values above 4 - moderate multicollinearity; above 10 - strong multicollinearity


What if we wanted to include all of the variables in our dataset?
```{r}
scores %>%
  ggpairs(ggplot2::aes(fill=gender),progress = F)+
  scale_fill_brewer(palette = "Dark2")
```


Run a multiple linear regression
```{r}
scores$education <- as.numeric(scores$education)

model3 <- lm(scores$SATV ~ scores$SATQ + scores$ACT + scores$age + scores$education + scores$gender)
summary(model3)
```


T-tests for Beta1:

* SATQ: p-value = 0.00% < 5% (reject the null) -> There is a linear relationship between SATQ and SATV scores. 
* ACT: p-value = 0.00% < 5% (reject the null) -> There is a linear relationship between ACT and SATV scores. 
* Age: p-value = 6.60% > 5% (fail to reject the null) -> There is no linear relationship between age and SATV scores.
* Education: p-value = 72.08% > 5% (fail to reject the null) -> There is no linear relationship between education and SATV scores.
* Gender: p-value = 1.42% < 5 % (reject the null) -> There is a linear relationship between gender and SATV scores. 

ANOVA for Regression:

* F-stat(5,681) = 122.8, p-value = 0.00% < 5% (reject the null)
* The overall model is worthwhile.

Overall:

* The estimated regression line equation: SATV = 136.25 + 0.48(SATQ)+6.61(ACT)-0.74(Age)+0.97(Education)+16.56(Men).  
* 47.41% of the variability in the SAT verbal scores was explained by the model as a whole.


## F-test for nested models

Run F-test for comparing nested models
```{r}
anova(model1,model2,model3)
```
p-value below 5% indicates that the new model is an improvement over the previous one


## Exporting regression results

Use stargazer package to export regression results into your current working directory
```{r results='asis'}
stargazer(model1,model2,model3,
type="html",
out="Regression results.doc")
```




# Optional

## Simple logistic regression

It is used to explain/predict one binary variable using one quantitative independent variables.

```{r}
summary(glm(scores$gender ~ scores$SATQ, family = binomial))
```


## Multiple logistic regression

It is used to explain/predict one binary variable using multiple explanatory variables (one of which has to be quantitative).

```{r}
summary(glm(scores$gender ~ scores$SATQ + scores$SATV, family = binomial))
```
